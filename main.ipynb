{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# sources:\n",
    "\n",
    "## audio preparation:\n",
    "* https://www.tensorflow.org/tutorials/audio/simple_audio\n",
    "* https://www.tensorflow.org/io/tutorials/audio\n",
    "\n",
    "## siamese network:\n",
    "* https://github.com/hlamba28/One-Shot-Learning-with-Siamese-Networks\n",
    "\n",
    "## misc:\n",
    "* https://gitlab.tu-berlin.de/dl4aed/dl4aed-lectures/blob/master/04-audio-preprocessing.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "# install and update required packages\n",
    "python3 -m pip install --upgrade pip -q\n",
    "python3 -m pip install -r requirements.txt -q\n",
    "python3 -m pip install --no-deps tensorflow-io==0.17.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%reload_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "''' Small hack to restart kernel after netbook ran to free GPU memory '''\n",
    "## restart jupyter kernel to free all memory in notebook\n",
    "from IPython.display import display_html\n",
    "def restartkernel():\n",
    "    display_html(\"<script>Jupyter.notebook.kernel.restart()</script>\",raw=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "''' Some imports '''\n",
    "import tensorflow as tf\n",
    "assert tf.__version__ >= \"2.4.0\"\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "''' Allow typical dynamic GPU memory allocation and read config'''\n",
    "from utils import load_config, save_config, allow_growth, update\n",
    "allow_growth()\n",
    "\n",
    "# read the config file\n",
    "# it includes more or less all hyperparameter used in the model and preprocessing/training step\n",
    "config = load_config(verbose=0)\n",
    "\n",
    "# some other configuration (*.py)\n",
    "import configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "''' Parsing CLI arguments and overwriting config '''\n",
    "from argument_parser import parse_arguments\n",
    "parsed_arguments, _ = parse_arguments()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# overwrite config\n",
    "config = update(config, configuration.config)\n",
    "config = update(config, parsed_arguments.__dict__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"WANDB_PROJECT\"] = \"training\"\n",
    "os.environ[\"WANDB_ENTITY\"] = \"dl4aed\"\n",
    "os.environ[\"WANDB_API_KEY\"] = \"****\"\n",
    "os.environ[\"WANDB_MODE\"] = \"run\" #or \"dryrun\"\n",
    "os.environ[\"WANDB_NOTEBOOK_NAME\"] = \"model\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "from wandb_utils import WandbWrapper\n",
    "wandb_wrapper = WandbWrapper(config)\n",
    "config = wandb_wrapper.get_config()\n",
    "''';"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# extract parameter classes\n",
    "data_parameter = config[\"data_parameter\"]\n",
    "model_parameter = config[\"model_parameter\"]\n",
    "training_parameter = config[\"training_parameter\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "''' Some small amount of reproducibility '''\n",
    "tf.random.set_seed(training_parameter[\"seed\"])\n",
    "np.random.seed(training_parameter[\"seed\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "''' Create model and save config '''\n",
    "from network import Network\n",
    "network = Network(model_parameter, training_parameter)\n",
    "network.compile()\n",
    "network.save()\n",
    "# save config into model path\n",
    "save_config(data_parameter, model_parameter, training_parameter, network)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = {}\n",
    "config['data_root'] = 'gtzan'\n",
    "config['noise_path'] = '/media/datasets/fsdkaggle2018/FSDKaggle2018.meta/test_post_competition_scoring_clips.csv'\n",
    "config['sample_rate'] = 22050\n",
    "config['nfft'] = 512\n",
    "config['window'] = 512\n",
    "config['stride'] = 256\n",
    "config['mels'] = 64\n",
    "config['fmin_mels'] = 0\n",
    "config['fmax_mels'] = 8000\n",
    "config['time_mask'] = 10\n",
    "config['freq_mask'] = 10\n",
    "config['noise_threshold'] = 1 # add noise to only 0.3\n",
    "config['beta'] = 0.5 # noise strength when mixing mel spectrograms\n",
    "config['SNR'] = 5\n",
    "config['noise_root'] = '/media/datasets/fsdkaggle2018/FSDKaggle2018.audio_test/'\n",
    "config['shuffle_batch_size'] = 64\n",
    "\n",
    "from preprocessor import Preprocessor\n",
    "y = Preprocessor(config=config)\n",
    "y.create_logger()\n",
    "\n",
    "y.set_config({'fade': 10000,\n",
    "              'epsilon': 0.1,\n",
    "              'roll_val': 15,\n",
    "              'top_db': 80,\n",
    "              'shift_val': 3,\n",
    "              'bins_per_octave': 12,\n",
    "              'param_db': 10,\n",
    "              'train_size': 0.7,\n",
    "              'val_size': 0.2,\n",
    "              'test_size': 0.1,\n",
    "              'noisy_samples': 5})\n",
    "\n",
    "y.load_data(data_dir=\"/media/datasets/tfds/\")\n",
    "\n",
    "for mode in y.available_modi:\n",
    "    y.offline_preprocessing(mode)\n",
    "y.save_mels()\n",
    "\n",
    "train_ds = y.train_ds\n",
    "val_ds = y.val_ds\n",
    "test_ds = y.test_ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "''' Training procedure '''\n",
    "AUTOTUNE = tf.data.AUTOTUNE\n",
    "\n",
    "network.fit(train_ds, epochs=training_parameter[\"epochs\"],\n",
    "                   initial_epoch=network.epoch, max_queue_size=AUTOTUNE,\n",
    "                   workers=AUTOTUNE, use_multiprocessing=False, callbacks=network.callbacks)# + [wandb_wrapper.get_callback()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "''' Evaluation procedure '''\n",
    "#network.evaluate(test_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# restart kernel to free GPU mem\n",
    "restartkernel()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
