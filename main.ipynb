{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# sources:\n",
    "\n",
    "## audio preparation:\n",
    "* https://www.tensorflow.org/tutorials/audio/simple_audio\n",
    "* https://www.tensorflow.org/io/tutorials/audio\n",
    "\n",
    "## siamese network:\n",
    "* https://github.com/hlamba28/One-Shot-Learning-with-Siamese-Networks\n",
    "\n",
    "## misc:\n",
    "* https://gitlab.tu-berlin.de/dl4aed/dl4aed-lectures/blob/master/04-audio-preprocessing.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "# install and update required packages\n",
    "python3 -m pip install --upgrade pip -q\n",
    "python3 -m pip install -r requirements.txt -q\n",
    "python3 -m pip install --no-deps tensorflow-io==0.17.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%reload_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "''' Small hack to restart kernel after netbook ran to free GPU memory '''\n",
    "## restart jupyter kernel to free all memory in notebook\n",
    "from IPython.display import display_html\n",
    "def restartkernel():\n",
    "    display_html(\"<script>Jupyter.notebook.kernel.restart()</script>\",raw=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "''' Some imports '''\n",
    "import tensorflow as tf\n",
    "assert tf.__version__ >= \"2.4.0\"\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "''' Allow typical dynamic GPU memory allocation and read config'''\n",
    "from utils import load_config, save_config, allow_growth\n",
    "allow_growth()\n",
    "# read the config file\n",
    "# it includes more or less all hyperparameter used in the model and preprocessing/training step\n",
    "data_parameter, model_parameter, training_parameter = load_config(verbose=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "''' Parsing CLI arguments and overwriting config '''\n",
    "from argument_parser import parse_arguments, overwrite_config\n",
    "parsed_arguments, _ = parse_arguments()\n",
    "overwrite_config(parsed_arguments, data_parameter, model_parameter, training_parameter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "''' Some small amount of reproducibility '''\n",
    "tf.random.set_seed(training_parameter[\"seed\"])\n",
    "np.random.seed(training_parameter[\"seed\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "''' Create model and save config '''\n",
    "from network import Network\n",
    "network = Network(model_parameter, training_parameter)\n",
    "network.compile()\n",
    "network.save()\n",
    "# save config into model path\n",
    "save_config(data_parameter, model_parameter, training_parameter, network)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "''' Load data and prepare datasets '''\n",
    "from data_generator import create_train_data, create_test_data\n",
    "train_dataset = create_train_data(training_parameter)\n",
    "test_dataset = create_test_data(training_parameter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "''' Training procedure '''\n",
    "AUTOTUNE = tf.data.experimental.AUTOTUNE\n",
    "\n",
    "network.fit(train_dataset, epochs=training_parameter[\"epochs\"],\n",
    "                   initial_epoch=network.epoch, max_queue_size=AUTOTUNE,\n",
    "                   workers=AUTOTUNE, use_multiprocessing=False, callbacks=network.callbacks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "''' Evaluation procedure '''\n",
    "network.evaluate(test_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "''' Current junkyard '''\n",
    "# from sklearn.metrics import confusion_matrix, multilabel_confusion_matrix, classification_report, ConfusionMatrixDisplay\n",
    "\n",
    "# some minor visual inspection\n",
    "for ((x1, x2), label) in test_dataset:\n",
    "    for x1_, x2_, label_ in zip(x1,x2,label):\n",
    "        plt.imshow(x1_)\n",
    "        plt.show()\n",
    "        plt.imshow(x2_)\n",
    "        plt.show()\n",
    "        print(label_.numpy())\n",
    "        print(tf.cast(tf.round(\n",
    "            network.predict_on_batch([tf.expand_dims(x1_, axis=0),tf.expand_dims(x2_, axis=0)])\n",
    "        ), dtype=tf.bool).numpy())\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# restart kernel to free GPU mem\n",
    "restartkernel()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
