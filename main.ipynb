{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# sources:\n",
    "\n",
    "## audio preparation:\n",
    "* https://www.tensorflow.org/tutorials/audio/simple_audio\n",
    "* https://www.tensorflow.org/io/tutorials/audio\n",
    "\n",
    "## siamese network:\n",
    "* https://github.com/hlamba28/One-Shot-Learning-with-Siamese-Networks\n",
    "\n",
    "## misc:\n",
    "* https://gitlab.tu-berlin.de/dl4aed/dl4aed-lectures/blob/master/04-audio-preprocessing.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "# install and update required packages\n",
    "python3 -m pip install --upgrade pip -q\n",
    "python3 -m pip install -r requirements.txt -q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%reload_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "''' Small hack to restart kernel after netbook ran to free GPU memory '''\n",
    "## restart jupyter kernel to free all memory in notebook\n",
    "from IPython.display import display_html\n",
    "def restartkernel():\n",
    "    display_html(\"<script>Jupyter.notebook.kernel.restart()</script>\",raw=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "''' Some imports '''\n",
    "import tensorflow as tf\n",
    "assert tf.__version__ >= \"2.4.0\"\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "''' Allow typical dynamic GPU memory allocation and read config'''\n",
    "from utils import load_config, save_config, allow_growth, update\n",
    "allow_growth()\n",
    "\n",
    "# read the config file\n",
    "# it includes more or less all hyperparameter used in the model and preprocessing/training step\n",
    "config = load_config(verbose=0)\n",
    "\n",
    "# some other configuration (*.py)\n",
    "import configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "''' Parsing CLI arguments and overwriting config '''\n",
    "from argument_parser import parse_arguments\n",
    "parsed_arguments, _ = parse_arguments()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# overwrite config\n",
    "config = update(config, configuration.config)\n",
    "config = update(config, parsed_arguments.__dict__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"WANDB_PROJECT\"] = \"resnet-experiments\"\n",
    "os.environ[\"WANDB_ENTITY\"] = \"dl4aed\"\n",
    "os.environ[\"WANDB_API_KEY\"] = \"***\"\n",
    "os.environ[\"WANDB_MODE\"] = \"dryrun\" #or \"run\"\n",
    "os.environ[\"WANDB_NOTEBOOK_NAME\"] = \"model\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from wandb_utils import WandbWrapper\n",
    "wandb_wrapper = WandbWrapper(config)\n",
    "config = wandb_wrapper.get_config()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# extract parameter classes\n",
    "data_parameter = config[\"data_parameter\"]\n",
    "model_parameter = config[\"model_parameter\"]\n",
    "training_parameter = config[\"training_parameter\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "''' Some small amount of reproducibility '''\n",
    "tf.random.set_seed(training_parameter[\"seed\"])\n",
    "np.random.seed(training_parameter[\"seed\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "''' Create model and save config '''\n",
    "from network import Network\n",
    "network = Network(model_parameter, training_parameter)\n",
    "network.compile()\n",
    "#network.save()\n",
    "# save config into model path\n",
    "#save_config(data_parameter, model_parameter, training_parameter, network)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = {}\n",
    "config['data_root'] = 'gtzan'\n",
    "config['noise_path'] = '/media/datasets/fsdkaggle2018/FSDKaggle2018.meta/test_post_competition_scoring_clips.csv'\n",
    "config['sample_rate'] = 22050\n",
    "config['nfft'] = 2048\n",
    "config['window'] = 2048\n",
    "config['stride'] = 1024\n",
    "config['mels'] = 64\n",
    "config['fmin_mels'] = 0\n",
    "config['fmax_mels'] = 8000\n",
    "config['time_mask'] = 10\n",
    "config['freq_mask'] = 10\n",
    "config['noise_threshold'] = 1 # add noise to only 0.3\n",
    "config['beta'] = 0.5 # noise strength when mixing mel spectrograms\n",
    "config['SNR'] = 1.\n",
    "config['noise_root'] = '/media/datasets/fsdkaggle2018/FSDKaggle2018.audio_test/'\n",
    "config['shuffle_buffer_size'] = 1000\n",
    "config['batch_size'] = 64\n",
    "\n",
    "from preprocessor import Preprocessor\n",
    "prep = Preprocessor(config=config)\n",
    "prep.create_logger()\n",
    "\n",
    "prep.set_config({'fade': 10000,\n",
    "              'epsilon': 0.1,\n",
    "              'roll_val': 1024,\n",
    "              'top_db': 80,\n",
    "              'shift_val': 3,\n",
    "              'bins_per_octave': 12,\n",
    "              'param_db': 10,\n",
    "              'train_size': 0.7,\n",
    "              'val_size': 0.2,\n",
    "              'test_size': 0.1,\n",
    "              'noisy_samples': 5,\n",
    "              \"common_divider\": 64,})\n",
    "\n",
    "prep.load_data(data_dir=\"/media/datasets/tfds/\")\n",
    "for mode in prep.available_modi:\n",
    "    prep.offline_preprocessing(mode)\n",
    "prep.save_mels()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "prep.load_mels()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "prep.launch_trainval_pipeline(mode=\"train\")\n",
    "prep.launch_trainval_pipeline(mode=\"val\")\n",
    "prep.launch_test_pipeline()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "''' Training procedure '''\n",
    "history = network.fit(prep.train_ds, validation_data=prep.val_ds, epochs=training_parameter[\"epochs\"],\n",
    "                   initial_epoch=network.epoch, callbacks=network.callbacks + [wandb_wrapper.get_callback(save_model=False)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "pd.DataFrame.from_dict(history.history).plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "''' Evaluation procedure '''\n",
    "import wandb\n",
    "\n",
    "collect_embeddings = []\n",
    "for elem in prep.val_ds:\n",
    "    embedding = network.predict_embedding_on_batch(elem[0])\n",
    "    collect_embeddings += [embedding]\n",
    "embeddings = tf.concat(collect_embeddings, axis=0)\n",
    "print(embeddings.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = tf.reshape(embeddings,(-1,embeddings.shape[-1]))\n",
    "from sklearn.manifold import TSNE\n",
    "X_embedded = TSNE(n_components=2).fit_transform(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "from matplotlib.ticker import NullFormatter\n",
    "\n",
    "# https://stackoverflow.com/a/57222323\n",
    "from itertools import cycle\n",
    "prop_cycle = plt.rcParams['axes.prop_cycle']\n",
    "colors = cycle(prop_cycle.by_key()['color'])\n",
    "\n",
    "# Create figure\n",
    "fig = plt.figure(figsize=(8, 8))\n",
    "# Add scatter plot\n",
    "ax = fig.add_subplot(111)\n",
    "ax.scatter(X_embedded[:, 0], X_embedded[:, 1], alpha=0.05)\n",
    "for i in range(10):\n",
    "    sub_images = 10\n",
    "    ax.scatter(X_embedded[i*sub_images:(i+1)*sub_images, 0], X_embedded[i*sub_images:(i+1)*sub_images, 1], alpha=0.5, c=next(colors))\n",
    "ax.xaxis.set_major_formatter(NullFormatter())\n",
    "ax.yaxis.set_major_formatter(NullFormatter())\n",
    "ax.axis('tight')\n",
    "wandb.log({\"embedding\": wandb.Image(plt)})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "for elem in prep.val_ds:\n",
    "    prediction = network.predict_on_batch(elem[0])\n",
    "    for (x, y) in list(zip(elem[0], prediction))[:10]:\n",
    "        x = x[...,0].numpy().astype(np.float32).T\n",
    "        y = y[...,0].astype(np.float32).T\n",
    "        wandb_wrapper.post_plt_image(x, y, title=\"Images\", tag=\"side-by-side-images\")\n",
    "        wandb_wrapper.post_plt_histogram(x, y, title=\"Histogram\", tag=\"overlay-histogram\", alpha=0.35, bins=50)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# restart kernel to free GPU mem\n",
    "#restartkernel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "collect_embeddings = []\n",
    "collect_labels = []\n",
    "for elem in prep.test_ds:\n",
    "    for (x, y) in zip(elem[0], elem[1]):\n",
    "        prediction = network.predict_embedding_on_batch(x[np.newaxis])\n",
    "        collect_embeddings += [prediction]\n",
    "        collect_labels += [y]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings = tf.concat(collect_embeddings, axis=0)\n",
    "labels = np.concatenate(collect_labels, axis=0)\n",
    "x = tf.reshape(embeddings,(-1,embeddings.shape[-1]))\n",
    "from sklearn.manifold import TSNE\n",
    "X_embedded = TSNE(n_components=2).fit_transform(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_classes = 10\n",
    "collect_colors_markers = {}\n",
    "\n",
    "from itertools import cycle\n",
    "prop_cycle = plt.rcParams['axes.prop_cycle']\n",
    "colors = cycle(prop_cycle.by_key()['color'])\n",
    "#markers = cycle(('x', ',', '+', '.', 'o', '*'))\n",
    "markers = cycle(('o', ','))\n",
    "\n",
    "for i in range(num_classes):\n",
    "    collect_colors_markers[i] = (next(colors), next(markers))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "from matplotlib.ticker import NullFormatter\n",
    "\n",
    "# Create figure\n",
    "fig = plt.figure(figsize=(8, 8))\n",
    "# Add scatter plot\n",
    "ax = fig.add_subplot(111)\n",
    "\n",
    "for embedding, label in zip(X_embedded, labels):\n",
    "    ax.scatter(embedding[0], embedding[1], alpha=0.5, c=collect_colors_markers[label][0], marker=collect_colors_markers[label][1])\n",
    "\n",
    "ax.xaxis.set_major_formatter(NullFormatter())\n",
    "ax.yaxis.set_major_formatter(NullFormatter())\n",
    "ax.axis('tight')\n",
    "wandb.log({\"test embedding - label colored\": wandb.Image(plt)})"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
