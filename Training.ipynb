{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "# install and update required packages\n",
    "python3 -m pip install --upgrade pip -q\n",
    "python3 -m pip install -r requirements.txt -q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%reload_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "''' W&B env. variables '''\n",
    "import os\n",
    "os.environ[\"WANDB_PROJECT\"] = \"report-experiments\"\n",
    "os.environ[\"WANDB_ENTITY\"] = \"dl4aed\"\n",
    "os.environ[\"WANDB_API_KEY\"] = \"***\"\n",
    "os.environ[\"WANDB_MODE\"] = \"dryrun\" #or \"run\"\n",
    "os.environ[\"WANDB_NOTEBOOK_NAME\"] = \"Training\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "''' Some imports '''\n",
    "import tensorflow as tf\n",
    "assert tf.__version__ >= \"2.4.0\"\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "''' Allow typical dynamic GPU memory allocation'''\n",
    "from utils import load_config, save_config, allow_growth, update\n",
    "allow_growth()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "''' Read config, parsing CLI arguments and overwriting config '''\n",
    "from argument_parser import parse_arguments\n",
    "\n",
    "# read the config file\n",
    "# it includes more or less all hyperparameter used in the model and preprocessing/training step\n",
    "config = load_config(verbose=0)\n",
    "\n",
    "# read args\n",
    "parsed_arguments = parse_arguments()\n",
    "\n",
    "# overwrite config\n",
    "config = update(config, parsed_arguments)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from wandb_utils import WandbWrapper\n",
    "# sync config with W&B\n",
    "wandb_wrapper = WandbWrapper(config)\n",
    "config = wandb_wrapper.get_config()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# extract parameter classes\n",
    "data_parameter = config[\"data_parameter\"]\n",
    "model_parameter = config[\"model_parameter\"]\n",
    "training_parameter = config[\"training_parameter\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "''' Some small amount of reproducibility '''\n",
    "tf.random.set_seed(training_parameter[\"seed\"])\n",
    "np.random.seed(training_parameter[\"seed\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "''' Create model and save config '''\n",
    "from network import Network\n",
    "network = Network(model_parameter, training_parameter)\n",
    "network.compile()\n",
    "network.save()\n",
    "# save config into model path\n",
    "save_config(data_parameter, model_parameter, training_parameter, network)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "''' Data pipeline procedure '''\n",
    "from preprocessor import Preprocessor\n",
    "prep = Preprocessor(config=data_parameter)\n",
    "prep.create_logger()\n",
    "prep.load_mels()\n",
    "prep.launch_trainval_pipeline(mode=\"train\")\n",
    "prep.launch_trainval_pipeline(mode=\"val\")\n",
    "prep.launch_test_pipeline(mode=\"fma\")\n",
    "prep.launch_test_pipeline(mode=\"test\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "''' Training procedure '''\n",
    "from callbacks import *\n",
    "additional_callbacks = []\n",
    "additional_callbacks += [CreateEmbedding(network, training_parameter[\"embedding_period\"], prep.test_ds, model_parameter[\"num_classes\"])]\n",
    "additional_callbacks += [ReconstructImages(network, training_parameter[\"reconstruction_period\"], prep.test_ds, wandb_wrapper)]\n",
    "additional_callbacks += [wandb_wrapper.get_callback(save_model=False)]\n",
    "\n",
    "history = network.fit(prep.train_ds, validation_data=prep.val_ds, epochs=training_parameter[\"epochs\"],\n",
    "                   initial_epoch=network.epoch, callbacks=network.callbacks + additional_callbacks)\n",
    "\n",
    "pd.DataFrame.from_dict(history.history).plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "''' Evaluation procedure '''\n",
    "for mode in [\"test\", \"fma\"]:\n",
    "    print(f\"Creating embedding for {mode}\")\n",
    "    ce = CreateEmbedding(network, None, prep.datasets[mode], model_parameter[\"num_classes\"])\n",
    "    embeddings, labels = ce.create_embedding()\n",
    "    print(\"Saving embedding as numpy file\")\n",
    "    np.save(f\"{network.model_path}{mode}_embeddings.npy\", embeddings, allow_pickle=True)\n",
    "    np.save(f\"{network.model_path}{mode}_labels.npy\", labels, allow_pickle=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
